# 斯坦福 NLP 课程 | 第 19 讲 - AI 安全偏见与公平

> 原文：[`blog.csdn.net/ShowMeAI/article/details/124669846`](https://blog.csdn.net/ShowMeAI/article/details/124669846)

![](img/aebcb87e9c0384c772533cd04ec6dd1d.png)

*   作者：[韩信子](https://github.com/HanXinzi-AI)@[ShowMeAI](http://www.showmeai.tech/)，路遥@[ShowMeAI](http://www.showmeai.tech/)，奇异果@[ShowMeAI](http://www.showmeai.tech/)
*   [教程地址](http://www.showmeai.tech/tutorials/36)：[`www.showmeai.tech/tutorials/36`](http://www.showmeai.tech/tutorials/36)
*   [本文地址](http://www.showmeai.tech/article-detail/257)：[`www.showmeai.tech/article-detail/257`](http://www.showmeai.tech/article-detail/257)
*   声明：版权所有，转载请联系平台与作者并注明出处
*   收藏[ShowMeAI](http://www.showmeai.tech/)查看更多精彩内容

* * *

![AI 安全偏见与公平](img/4c227cbce849e83cefc1c60411fe82e6.png)

[ShowMeAI](http://www.showmeai.tech/)为**斯坦福 CS224n**《自然语言处理与深度学习(Natural Language Processing with Deep Learning)》课程的全部课件，做了**中文翻译和注释**，并制作成了 GIF 动图！视频和课件等资料的获取方式见**文末**。

* * *

# 1.Bias in the Vision and Language of Artificial Intelligence

![Bias in the Vision and Language of Artificial Intelligence](img/738e18b7e5c0128749b2eba2f641ba60.png)

# 2.Prototype Theory

![What do you see?](img/57bb8617701ad83b024310926e168b54.png)

*   Bananas
*   Stickers
*   Dole Bananas
*   Bananas at a store
*   Bananas on shelves
*   Bunches of bananas
*   Bananas with stickers on them
*   Bunches of bananas with stickers on them on shelves in a store

…We don’t tend to say Yellow Bananas

![What do you see?](img/717a8c246cb19f1a00484abcdc856e9c.png)

![What do you see?](img/341a582241119608987fab86912f2bb2.png)

![What do you see?](img/6964e182df8a359c85be33474ad60d76.png)

![Prototype Theory](img/f6c715062e21724cf9fd110bc7ce817b.png)

*   Prototype Theory
    *   分类的目的之一是减少刺激行为和认知上可用的比例的无限差异
    *   物品的一些核心、原型概念可能来自于存储的对象类别的典型属性 (Rosch, 1975)
    *   也可以存储范例 (Wu & Barsalou, 2009)

![Prototype Theory](img/861a62d80c3bcf69f9516f2f6ef6a2d3.png)

*   Doctor —— Female Doctor
*   大多数受试者忽视了医生是女性的可能性，包括男性、女性和自称女权主义者的人

![Prototype Theory](img/29e8de5ea8746c8f13bc884649233c45.png)

![World Learning from text](img/b5a882b47ff1f8baefd53098c2593913.png)

*   Human Reporting Bias
    *   murdered 是 blinked 出现次数的十倍
    *   我们不倾向于提及眨眼和呼吸等事情

![Human Reporting Bias](img/549e67c69a4149133499e5ad9f7497b8.png)

*   Human Reporting Bias
    *   人们写作中的行为、结果或属性的频率并不反映真实世界的频率，也不反映某一属性在多大程度上是某一类个体的特征。
    *   更多关于我们处理世界和我们认为非凡的东西的实际情况。这影响到我们学习的一切。

![Human Reporting Bias](img/286880a218a83865a63ecd230059617a.png)

![Human Reporting Bias in Data](img/86a76693bc374123833ed959c00b1502.png)

![Human Reporting Bias in Data](img/3a7a5b9176d60a01434d274283e352fa.png)

*   Data 数据
    *   Reporting bias 报告偏见：人们分享的并不是真实世界频率的反映
    *   Selection Bias 选择偏差：选择不反映随机样本
    *   Out-group homogeneity bias 外群体同质性偏见：People tend to see outgroup members as more alike than ingroup members when comparing attitudes, values, personality traits, and other characteristics

*   Interpretation
    *   Confirmation bias 确认偏见：倾向于寻找、解释、支持和回忆信息，以确认一个人先前存在的信念或假设
    *   Overgeneralization 泛化过度：根据过于笼统和/或不够具体的信息得出结论
    *   Correlation fallacy 相关性谬误：混淆相关性和因果关系
    *   Automation bias 自动化偏差：人类倾向于喜欢来自自动化决策系统的建议，而不是没有自动化的相互矛盾的信息

# 3.Biases in Data

![Biases in Data](img/a8c9b4efe1ff60431139310dc9bdcea3.png)

![Biases in Data](img/e0a22bb145520b97634b11f02972a5c3.png)

*   Selection Bias 选择偏差：选择不反映随机样本

![Biases in Data](img/d70c9786d212315c745c7a3373b66b82.png)

*   Out-group homogeneity bias 外群体同质性偏见：在比较态度、价值观、个性特征和其他特征时，往往群体外的成员认为比群体内的成员更相似
*   这有些难以理解：意思就是左边的四只猫之间是非常不同的，但是在狗的眼里他们是相同的

![Biases in Data → Biased Data Representation](img/58e64917e16b748c98c5d7836550d14d.png)

*   Biases in Data → Biased Data Representation
*   你可能对你能想到的每一个群体都有适当数量的数据，但有些群体的表现不如其他群体积极。

![Biases in Data → Biased Labels](img/f752dedd6b0da1ad7976974112a2354a.png)

*   Biases in Data → Biased Labels
*   数据集中的注释将反映注释者的世界观

# 4.Biases in Interpretation

![Biases in Interpretation](img/a4b94aaf7e2c7644f2b1dcc7f7c68cea.png)

![Biases in Interpretation](img/4d6c258e00755b6fba9f13640d31db71.png)

*   Biases in Interpretation
    *   Confirmation bias 确认偏见：倾向于寻找、解释、支持和回忆信息，以确认一个人先前存在的信念或假设

![Biases in Interpretation](img/93c7b3635bbe7d0570eed748ce6ba058.png)

*   Biases in Interpretation
    *   Overgeneralization 泛化过度：根据过于笼统和/或不够具体的信息得出结论（相关：过拟合）

![Biases in Interpretation](img/82a775510c15a5ab9a3d6c3d24fd3707.png)

*   Biases in Interpretation
    *   Correlation fallacy 相关性谬误：混淆相关性和因果关系

![Biases in Interpretation](img/df4b4d7c87e727aa77ba401b239cf22a.png)

*   Biases in Interpretation
    *   Automation bias 自动化偏差：人类倾向于喜欢来自自动化决策系统的建议，而不是没有自动化的相互矛盾的信息

![Biases in Interpretation](img/4c6ac5cb71b22dd10c871a5be91b8aca.png)

*   会形成反馈循环
*   这被称为 Bias Network Effect 以及 Bias “Laundering”

![Human data perpetuates human biases. As ML learns from human data, the result is a bias network effect.](img/18350a3481bfb7be3edd1cdbdd169eba.png)

*   Human data perpetuates human biases. As ML learns from human data, the result is a bias network effect.
*   人类数据延续了人类的偏见。当 ML 从人类数据中学习时，结果是一个偏置网络效应。

# 5.BIAS = BAD ??

![BIAS = BAD ??](img/9f1775c3404e3e14864714190755e378.png)

![“Bias” can be Good, Bad, Neutral](img/639e942f8f29a4b2f1117e7dc866f04d.png)

*   统计以及 ML 中的偏差

    *   估计值的偏差：预测值与我们试图预测的正确值之间的差异
    *   “偏差”一词 b(如 y = mx + b)
*   认知偏见

    *   确认性偏差、近因性偏差、乐观性偏差
*   算法偏差

    *   对与种族、收入、性取向、宗教、性别和其他历史上与歧视和边缘化相关的特征相关的人的不公平、不公平或偏见待遇，何时何地在算法系统或算法辅助决策中体现出来”

![amplify injustice](img/baa818a9b2c410527423d138612e818e.png)

*   如何避免算法偏差，开发出不会放大差异的算法

# 6.Predicting Future Criminal Behavior

![Predicting Future Criminal Behavior](img/393c7facd1f2f743ce41a10fc689d734.png)

![Predicting Policing](img/b95f9ac478fddb526e9ba7a3802587c5.png)

*   Predicting Future Criminal Behavior
    *   算法识别潜在的犯罪热点
    *   基于之前报道的犯罪的地方，而不是已知发生在哪里
    *   从过去预测未来事件
    *   预测的是逮捕的地方而不是犯罪的地方

![Predicting Sentencing](img/12719bbf8b66909cf6ae6d660c7cab96.png)

*   Prater (白人)额定低风险入店行窃后，尽管两个武装抢劫;一次持械抢劫未遂。
*   Borden (黑色)额定高危后她和一个朋友(但在警察到来之前返回)一辆自行车和摩托车坐在外面。
*   两年后，Borden 没有被指控任何新的罪行。Prater 因重大盗窃罪被判 8 年有期徒刑。
*   系统默认认为黑人的犯罪风险高于白人

# 7.Automation Bias

![Automation Bias](img/f41e1df018f9c2c0049ca13f16a42533.png)

![Predicting Criminality](img/777912e374423157146c172727a12c2a.png)

*   以色列启动 Faception
*   Faception 是第一个科技领域的率先面市的，专有的计算机视觉和机器学习技术分析人员和揭示他们的个性只基于他们的面部图像。
*   提供专业的引擎从脸的形象识别“高智商”、“白领犯罪”、“恋童癖”，和“恐怖分子”。
*   主要客户为国土安全和公共安全。

![Predicting Criminality](img/f10c3e23dd1052c74140284cdab13746.png)

*   “Automated Inference on Criminality using Face Images” Wu and Zhang, 2016\. arXiv
*   1856 个紧密裁剪的面孔的图像，包括“通缉犯”ID 特定区域的照片
*   存在确认偏差和相关性偏差

# 8.Selection Bias + Experimenter’s Bias +Confirmation Bias + Correlation Fallacy +Feedback Loops

![Selection Bias + Experimenter’s Bias +Confirmation Bias + Correlation Fallacy +Feedback Loops](img/440c7caeece7dbcfbb21e18e8c8eebd1.png)

![Predicting Criminality - The Media Blitz](img/c771e3c7ede7150717cb5a7237bac9c3.png)

# 9.(Claiming to) Predict Internal Qualities Subject To Discrimination

![(Claiming to) Predict Internal Qualities Subject To Discrimination](img/087aa7d9a996ea806521e6faf4482dcb.png)

![Predicting Homosexuality](img/78258270b7441b580640d159c2fee0bf.png)

*   Wang and Kosinski, Deep neural networks are more accurate than humans at detecting sexual orientation from facial images, 2017.
*   “Sexual orientation detector” using 35,326 images from public profiles on a US dating website.
*   “与性取向的产前激素理论(PHT)相一致，男同性恋者和女同性恋者往往具有非典型的性别面部形态。”

![Predicting Homosexuality](img/bb97bd30b28d87af4dab486cf3a73991.png)

*   在自拍中，同性恋和异性恋之间的差异与打扮、表现和生活方式有关，也就是说，文化差异，而不是面部结构的差异
*   See our longer response on Medium, “Do Algorithms Reveal Sexual Orientation or Just Expose our Stereotypes?”
*   Selection Bias + Experimenter’s Bias + Correlation Fallacy

# 10.Selection Bias + Experimenter’s Bias + Correlation Fallacy

![Selection Bias + Experimenter’s Bias + Correlation Fallacy](img/3e2d798fcc736cbdd38a7088eabe1746.png)

# 11.Measuring Algorithmic Bias

![Measuring Algorithmic Bias](img/43b42f04be1da93059ba179c967fea4f.png)

![Evaluate for Fairness & Inclusion](img/b657dc39e4c5b9c38cca8c429ab62463.png)

*   评估公平性和包容性
    *   分类评估
        *   为每个创建（子组，预测）对。跨子组比较
    *   例如
        *   女性，面部检测
        *   男性，面部检测

![Evaluate for Fairness & Inclusion: Confusion Matrix](img/7e0f075df0fb79d599ac688f3142f596.png)

![Evaluate for Fairness & Inclusion](img/5b83a7942e2d53b0e48ed453c22a3073.png)

*   “机会平等”公平准则：子组的 recall 是相等的
*   “预测平价”公平准则：子组的 precision 是相等
*   选择评价指标的可接受的假阳性和假阴性之间的权衡

# 12.False Positives and False Negatives

![False Positives and False Negatives](img/fbd797cfb5d3767e75435bcfd0134a34.png)

![False Positives Might be Better than False Negatives](img/b13ea8b218b412ec7243afc8e5b6fd96.png)

*   False Positives Might be Better than False Negatives
    *   Privacy in Images
    *   Spam Filtering

![False Negatives Might be Better than False Positives](img/013d12ececd7a7ffc2865e92faf61592.png)

![AI Can Unintentionally Lead to Unjust Outcomes](img/02c0d7c3f8a72750cff5c779e763c5c5.png)

*   缺乏对数据和模型中的偏见来源的洞察力
*   缺乏对反馈循环的洞察力
*   缺乏细心，分类的评价
*   人类偏见在解释和接受结果

# 13.It’s up to us to influence how AI evolves.

![It’s up to us to influence how AI evolves.](img/70e4905850710f39f7701f7ffabb0112.png)

![Begin tracing out paths for the evolution of ethical AI](img/dc21b9580d8be29dd922205de5918478.png)

# 14.It’s up to us to influence how AI evolves. Here are some things we can do.

![It’s up to us to influence how AI evolves. Here are some things we can do.](img/cdab51262eede1f5be604254ea28a053.png)

# 15.Data

![Data](img/b8f39918b5756c6ab90df11e3daa6459.png)

![Data Really, Really Matters](img/e2c9b50b279b642ef115d72d3c3b12e3.png)

*   了解您的数据：偏差，相关性
*   从类似的分布放弃单一训练集/测试集
*   结合来自多个来源的输入
*   对于困难的用例使用 held-out 测试集
*   与专家讨论其他信号

![Understand Your Data Skews](img/695314bcf594532693a789af154f9437.png)

![Understand Your Data Skews](img/81f23d7734c0e8129390e27385cce9e5.png)

*   没有一个数据集是没有偏差的，因为这是一个有偏差的世界。重点是知道是什么偏差。

# 16.Machine Learning

![Machine Learning](img/bacaee9a64336e771ac9c135e001e80b.png)

![Use ML Techniques for Bias Mitigation and Inclusion](img/b15bc0527651393bb1705a66fad270d6.png)

*   Bias Mitigation 偏差缓解
    *   删除有问题的输出的信号
        *   刻板印象
        *   性别歧视，种族歧视，*-ism
        *   又称为“debiasing”

![Use ML Techniques for Bias Mitigation and Inclusion](img/cb1f78f5f3acf515aa19cb67d2c0cb9b.png)

*   Inclusion
    *   添加信号所需的变量
        *   增加模型性能
        *   注意性能很差的子组或数据片

# 17.Multi-task Learning to Increase Inclusion

![Multi-task Learning to Increase Inclusion](img/d522736a6306631dc72030527b6ef9ae.png)

![Multiple Tasks + Deep Learning for Inclusion: Multi-task Learning Example](img/eadc62f1da4d5b41df3ee0c5df700639.png)

*   与宾夕法尼亚大学 WWP 合作
*   直接与临床医生合作
*   目标
    *   系统警告临床医生如果企图自杀迫在眉睫
    *   几个训练实例可用时诊断的可行性

*   Benton, Mitchell, Hovy. Multi-task learning for Mental Health Conditions with Limited Social Media Data. EACL, 2017.

![Multiple Tasks + Deep Learning for Inclusion: Multi-task Learning Example](img/93cbe333903fdb5287e0392c8e98f270.png)

*   内部数据
    *   电子健康记录
        *   病人或病人家属提供
        *   包括心理健康诊断，自杀企图，竞赛
    *   社交媒体数据

*   代理数据
    *   Twitter 媒体数据
    *   代理心理健康诊断中使用自称诊断
        *   我被诊断出患有 X
        *   我试图自杀

![Single-Task: Logistic Regression, Deep Learning](img/ca56a9f80eaf03ee98abb53727f5323a.png)

![Multiple Tasks with Basic Logistic Regression](img/c0449c257a034869c0c75d41e1240a16.png)

![Multi-task Learning](img/582f6259cabb8d0c1aa9734c008d55b0.png)

![Improved Performance across Subgroups](img/f9a9c67c360625537103cfb93eed8093.png)

![Reading for the masses….](img/ff2cd637f16444b24be0c42f5f971dc3.png)

# 18.Adversarial Multi-task Learning to Mitigate Bias

![Adversarial Multi-task Learning to Mitigate Bias](img/811aa1ac34405e03631d5d7265edc7f2.png)

![Multitask Adversarial Learning](img/0c8fdad83c2be8b7be13a213494510c1.png)

![Equality of Opportunity in Supervised Learning](img/aa68a002f91ff8c4b82d5dafe65e6223.png)

*   考虑到真正正确的决策，分类器的输出决策应该在敏感特征之间是相同的。

# 19.Case Study: Conversation AI Toxicity

![Case Study: Conversation AI Toxicity](img/58d525c746d8932fdb19b4a7e42aa45f.png)

## 19.1 Measuring and Mitigating Unintended Bias in Text Classification

![Measuring and Mitigating Unintended Bias in Text Classification](img/a866f22d0a20f5b87f6bb1afae133a1f.png)

## 19.2 Conversation-AI & Research Collaboration

![Conversation-AI & Research Collaboration](img/8cf4647260a47d8d3ccadd92e38a4247.png)

*   Conversation-AI
    *   ML 提高大规模在线对话
*   Research Collaboration
    *   Jigsaw, CAT, several Google-internal teams, and external partners (NYTimes, Wikimedia, etc)

## 19.3 Perspective API

![Perspective API](img/b2e9bbf20310e1084f9c223cb2ad7eab.png)

## 19.4 Unintended Bias

![Unintended Bias](img/906fc5bf9c1c839dae73349d9fd35c37.png)

## 19.5 Bias Source and Mitigation

![Bias Source and Mitigation](img/91a2089fa81331cae94233ce85b0ff38.png)

*   偏见造成的数据不平衡

    *   经常袭击了有毒的身份所占比例评论
    *   长度问题
*   添加维基百科文章中假定的无毒数据来修复这种不平衡

    *   原始数据集有 127820 个例子
    *   4620 个补充的无毒例子

## 19.6 Measuring Unintended Bias - Synthetic Datasets

![Measuring Unintended Bias - Synthetic Datasets](img/04281fbd7b8e11a38767e8fdad9b4009.png)

*   挑战与真实数据
    *   现有数据集是小 and/or 有错误的相关性
    *   每个例子是完全独特的
*   Approach："bias madlibs”：一个综合生成的模板化数据集进行评估

## 19.7 Assumptions

![Assumptions](img/a63090b001b6257ab1f4fb07371c465a.png)

*   数据集是可靠的
    *   和产品相似的分布
    *   忽略注释器偏见
    *   没有因果分析

## 19.8 Deep Learning Model

![Deep Learning Model](img/3811b3ba869351e3e9e698e3c15b6de7.png)

*   深度学习模型
*   CNN 架构
*   预训练的 GloVe 嵌入
*   Keras 实现

## 19.9 Measuring Model Performance

![Measuring Model Performance](img/7f99497bb5654cb97370ca14a146a548.png)

## 19.10 Measuring Model Performance

![Measuring Model Performance](img/d5ecdf83edd15409541df4bd2093d082.png)

## 19.11 Types of Bias

![Types of Bias](img/c40e6cd5d5064f885fd7d27f9962d4d1.png)

*   Low Subgroup Performance
    *   模型在子组注释上的性能比在总体注释上差
*   Metric : Subgroup AUC

![Types of Bias](img/04671d4fe3e94ee7070882a3959533b0.png)

*   Subgroup Shift (Right)
    *   该模型系统地对来自子组的评价打分更高
    *   Metric: BPSN AUC
    *   (Background Positive Subgroup Negative)

*   Subgroup Shift (Left)
    *   该模型系统地对来自子组的评价打分较低
    *   Metric: BNSP AUC
    *   (Background Negative Subgroup Positive)

## 19.12 Results

![Results](img/623449bb763f355c257e0134efe7a034.png)

# 20.Release Responsibly

![Release Responsibly](img/80b7574929f1e53924e301afa574ec6a.png)

![Model Cards for Model Reporting](img/244c2ff4367fee9aafd5c7588bf1081b.png)

*   目前还没有模型发布时报告模型效果的 common practice
*   What It Does
    *   一份关注模型性能透明度的报告，以鼓励负责任的人工智能的采用和应用
*   How It Works
    *   这是一个容易发现的和可用的工件在用户旅程中重要的步骤为一组不同的用户和公共利益相关者
*   Why It Matter
    *   它使模型开发人员有责任发布高质量和公平的模型
    *   Intended Use, Factors and Subgroups

![Intended Use, Factors and Subgroups, Metrics and Data, Considerations, Recommendations](img/8408385cf83f1dedd5a002c414a8f9a2.png)

![Disaggregated Intersectional Evaluation](img/8e66b3b4cbf2e5fc943499373e5316e2.png)

# 21.Moving from majority representation… to diverse representation… for ethical AI

![Moving from majority representation... to diverse representation... for ethical AI](img/c37eb2b36330ed0bab2a0936d43e9d9c.png)

# 22.Thanks

![](img/a11dbfc1153ce2ac1b44427b2b474698.png)

# 23.视频教程

可以点击 [B 站](https://www.bilibili.com/video/BV1Yo4y1D7FW?p=19) 查看视频的【双语字幕】版本

[`player.bilibili.com/player.html?aid=376755412&page=19`](https://player.bilibili.com/player.html?aid=376755412&page=19)

【双语字幕+资料下载】斯坦福 CS224n | 深度学习与自然语言处理(2019·全 20 讲)

# 24.参考资料

*   [本讲带学的**在线阅翻页本**](https://blog.showmeai.tech/cs224n/lecture19-Safety-Bias-and-Fairness#/)
*   [《斯坦福 CS224n 深度学习与自然语言处理》**课程学习指南**](https://blog.showmeai.tech/cs224n/)
*   [《斯坦福 CS224n 深度学习与自然语言处理》**课程大作业解析**](https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS224n-Natural-Language-Processing-with-Deep-Learning/assignment-solutions)
*   [【**双语字幕视频**】斯坦福 CS224n | 深度学习与自然语言处理(2019·全 20 讲)](https://www.bilibili.com/video/BV1Yo4y1D7FW)
*   [**Stanford 官网** | CS224n: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)

# [**ShowMeAI**](http://www.showmeai.tech)系列教程推荐

*   [大厂技术实现 | 推荐与广告计算解决方案](http://www.showmeai.tech/tutorials/50)
*   [大厂技术实现 | 计算机视觉解决方案](http://www.showmeai.tech/tutorials/51)
*   [大厂技术实现 | 自然语言处理行业解决方案](http://www.showmeai.tech/tutorials/52)
*   [图解 Python 编程：从入门到精通系列教程](http://www.showmeai.tech/tutorials/56)
*   [图解数据分析：从入门到精通系列教程](http://www.showmeai.tech/tutorials/33)
*   [图解 AI 数学基础：从入门到精通系列教程](http://www.showmeai.tech/tutorials/83)
*   [图解大数据技术：从入门到精通系列教程](http://www.showmeai.tech/tutorials/84)
*   [图解机器学习算法：从入门到精通系列教程](http://www.showmeai.tech/tutorials/34)
*   [机器学习实战：手把手教你玩转机器学习系列](http://www.showmeai.tech/tutorials/41)
*   [深度学习教程 | 吴恩达专项课程 · 全套笔记解读](http://www.showmeai.tech/tutorials/35)
*   [自然语言处理教程 | 斯坦福 CS224n 课程 · 课程带学与全套笔记解读](http://www.showmeai.tech/tutorials/36)

# NLP 系列教程文章

*   [NLP 教程(1)- 词向量、SVD 分解与 Word2vec](http://showmeai.tech/article-detail/230)
*   [NLP 教程(2)- GloVe 及词向量的训练与评估](http://showmeai.tech/article-detail/232)
*   [NLP 教程(3)- 神经网络与反向传播](http://showmeai.tech/article-detail/234)
*   [NLP 教程(4)- 句法分析与依存解析](http://www.showmeai.tech/article-detail/237)
*   [NLP 教程(5)- 语言模型、RNN、GRU 与 LSTM](http://www.showmeai.tech/article-detail/239)
*   [NLP 教程(6)- 神经机器翻译、seq2seq 与注意力机制](http://www.showmeai.tech/article-detail/242)
*   [NLP 教程(7)- 问答系统](http://www.showmeai.tech/article-detail/245)
*   [NLP 教程(8)- NLP 中的卷积神经网络](http://www.showmeai.tech/article-detail/247)
*   [NLP 教程(9)- 句法分析与树形递归神经网络](http://www.showmeai.tech/article-detail/255)

# 斯坦福 CS224n 课程带学详解

*   [斯坦福 NLP 课程 | 第 1 讲 - NLP 介绍与词向量初步](http://showmeai.tech/article-detail/231)
*   [斯坦福 NLP 课程 | 第 2 讲 - 词向量进阶](http://showmeai.tech/article-detail/233)
*   [斯坦福 NLP 课程 | 第 3 讲 - 神经网络知识回顾](http://showmeai.tech/article-detail/235)
*   [斯坦福 NLP 课程 | 第 4 讲 - 神经网络反向传播与计算图](http://showmeai.tech/article-detail/236)
*   [斯坦福 NLP 课程 | 第 5 讲 - 句法分析与依存解析](http://www.showmeai.tech/article-detail/238)
*   [斯坦福 NLP 课程 | 第 6 讲 - 循环神经网络与语言模型](http://www.showmeai.tech/article-detail/240)
*   [斯坦福 NLP 课程 | 第 7 讲 - 梯度消失问题与 RNN 变种](http://www.showmeai.tech/article-detail/241)
*   [斯坦福 NLP 课程 | 第 8 讲 - 机器翻译、seq2seq 与注意力机制](http://www.showmeai.tech/article-detail/243)
*   [斯坦福 NLP 课程 | 第 9 讲 - cs224n 课程大项目实用技巧与经验](http://www.showmeai.tech/article-detail/244)
*   [斯坦福 NLP 课程 | 第 10 讲 - NLP 中的问答系统](http://www.showmeai.tech/article-detail/246)
*   [斯坦福 NLP 课程 | 第 11 讲 - NLP 中的卷积神经网络](http://www.showmeai.tech/article-detail/248)
*   [斯坦福 NLP 课程 | 第 12 讲 - 子词模型](http://www.showmeai.tech/article-detail/249)
*   [斯坦福 NLP 课程 | 第 13 讲 - 基于上下文的表征与 NLP 预训练模型](http://www.showmeai.tech/article-detail/250)
*   [斯坦福 NLP 课程 | 第 14 讲 - Transformers 自注意力与生成模型](http://www.showmeai.tech/article-detail/251)
*   [斯坦福 NLP 课程 | 第 15 讲 - NLP 文本生成任务](http://www.showmeai.tech/article-detail/252)
*   [斯坦福 NLP 课程 | 第 16 讲 - 指代消解问题与神经网络方法](http://www.showmeai.tech/article-detail/253)
*   [斯坦福 NLP 课程 | 第 17 讲 - 多任务学习(以问答系统为例)](http://www.showmeai.tech/article-detail/254)
*   [斯坦福 NLP 课程 | 第 18 讲 - 句法分析与树形递归神经网络](http://www.showmeai.tech/article-detail/256)
*   [斯坦福 NLP 课程 | 第 19 讲 - AI 安全偏见与公平](http://www.showmeai.tech/article-detail/257)
*   [斯坦福 NLP 课程 | 第 20 讲 - NLP 与深度学习的未来](http://www.showmeai.tech/article-detail/258)

![](img/d762026cbf142061ada32b69ff2c765e.png)